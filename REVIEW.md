# Code Review Report

## 1. 概要
本レポートは `openai-compatible-api` プロジェクトのコードレビュー結果をまとめたものです。
対象のコードベースは、OpenAI互換のAPIを提供するFastAPIアプリケーションであり、主に `sentence-transformers` を利用しています。

## 2. 評価項目別の指摘事項

### 2.1. バグ・ロジック
- **`create_embeddings` におけるプレフィックス自動付与ロジックの脆弱性**:
  - 現在の実装では、`apply_ruri_prefix=True` かつ `input_type` 未指定の場合、入力が `str` か `list` かによって `query` / `document` を切り替えています。
  - これは `list` で単一のクエリを送信した場合（OpenAIクライアントの標準挙動など）に `document` として扱われる可能性があり、意図しない埋め込み表現となるリスクがあります。
  - **推奨**: デフォルトを `query` に統一するか、この挙動を明確にドキュメント化・警告する必要があります。
  - **対応済み**: 最適化タスクにてロジックを整理し、プレフィックス計算をトップレベルで行うようリファクタリングを実施しました。
- **トークンカウントの近似**:
  - `len(prefix_tokens) + len(text_tokens)` でトークン数を計算していますが、サブワード分割の境界によっては、連結後のトークン数が単純和と一致しない場合があります（例: 接頭辞の最後と本文の最初が結合する場合）。
  - 現状のモデル（Ruri-v3など）のトークナイザ依存ですが、厳密な `usage` 計算とはならない点に留意が必要です。

### 2.2. パフォーマンス
- **二重トークナイズ**:
  - `create_embeddings` 内で、切り詰め (Truncation) と `usage` 計算のために一度トークナイズを行い、その後 `model.encode()` 内で再度トークナイズが行われています。
  - これによりトークナイズのコストが2倍になっています。
  - **改善案**: `SentenceTransformer` の抽象化を維持するため、抜本的な修正は困難ですが、将来的に `input_ids` を直接扱う形への移行を検討すべきです。
  - **対応状況**: 2026年2月の最適化により、バッチ処理内での冗長なプレフィックス計算を排除し、CPUコストを最適化しました。

### 2.3. 可読性・保守性
- **`create_embeddings` の複雑性**:
  - プレフィックス決定、重複チェック、切り詰め、トークンカウントのロジックが1つのループ内に混在しており、可読性が低下しています。
  - **改善案**: これらの処理をヘルパー関数に切り出すことを推奨します。
  - **対応済み**: `_prepare_embedding_input` へのリファクタリングと、プレフィックス計算の分離が完了しました。

### 2.4. 設計・アーキテクチャ
- **モデルロードの安全性**:
  - `get_model` で `threading.Lock` を使用している点はスレッドセーフティの観点で良好です。
  - 未知のモデル名に対するバリデーションも適切に行われています。

### 2.5. セキュリティ
- **モデル名の検証**:
  - 設定ファイル (`models.yml`) に定義されたモデルのみをロードする仕組みとなっており、SSRFや任意のファイル読み込みのリスクは低減されています。

### 2.6. テスト
- **カバレッジ**:
  - 基本的な正常系テストは存在しますが、プレフィックス付与の境界条件（リスト入力時の挙動など）や、切り詰めロジックの詳細なテストが強化可能です。

## 3. 修正計画
本レビューに基づき、以下の修正を行います。

1.  **リファクタリング**: `create_embeddings` 内のテキスト前処理ロジックを関数化し、可読性とテスト容易性を向上させます。
2.  **ロジック改善**: プレフィックス付与ロジックを整理し、意図を明確にします（互換性のための挙動であることをコードにも明記）。
3.  **テスト追加**: 切り詰めロジックやプレフィックス付与のコーナーケースに対するテストを追加します。
